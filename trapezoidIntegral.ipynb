{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1469b33d-967e-4940-b978-5f54feb6da01",
   "metadata": {},
   "source": [
    "# Computing an Integral by the Trapezoid method using SparkSQL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578d1bc-1a39-4565-ae49-4739cb10f73f",
   "metadata": {},
   "source": [
    "*First import libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e817c879-bcef-4080-95e9-fe102ce344be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import FloatType, DoubleType\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11996331-3c5e-4bab-9c13-b2bc9465e86b",
   "metadata": {},
   "source": [
    "*Initialize SparkSession and SQLContext*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "68f3abec-4ab2-47af-bb7b-eb0392e43132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"TrapezoidMethod\").getOrCreate()      \n",
    "sqlContext = SQLContext(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973d853-8aa9-475f-8ee8-1b790e8942da",
   "metadata": {},
   "source": [
    "*Define integration Limits, Number of Partitions and UDFs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "65d1ae08-1020-4bbb-85ee-dcc870e9151b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.A(x0, x1)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.01      #Inferior Limit\n",
    "b = 0.1       #Superior Limit\n",
    "k = 100000     #Number of partitions\n",
    "h = (b-a)/k\n",
    "\n",
    "def interval(n) :\n",
    "    return a + n*h\n",
    "\n",
    "def f(x) :\n",
    "    return math.cos(1/x)\n",
    "\n",
    "def A(x0,x1) :\n",
    "    return (h/2)*(f(x0) + f(x1))\n",
    "\n",
    "spark.udf.register(\"interval\",interval,DoubleType())\n",
    "spark.udf.register(\"f\",f,DoubleType())\n",
    "spark.udf.register(\"A\",A,DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dda6e-f15d-4b69-a7e0-5bc2b56545af",
   "metadata": {},
   "source": [
    "*In the next code block we Calculate a DataFrame with the values for every point and the Area of every trapezoid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a58aa3e9-f43d-4a07-b5a6-cc980aba782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "| id|                  x0|                  x1|             f(x0)|             f(x1)|                area|\n",
      "+---+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "|  1|                0.01|           0.0100009|0.8623188722876839|0.8577271357502991|7.740207036170925E-7|\n",
      "|  2|           0.0100009|           0.0100018|0.8577271357502991|0.8530667813794596|7.698572627083914E-7|\n",
      "|  3|           0.0100018|           0.0100027|0.8530667813794596|0.8483382236202023|7.656322522498478E-7|\n",
      "|  4|           0.0100027|           0.0100036|0.8483382236202023|0.8435418820760986|7.613460475633354E-7|\n",
      "|  5|           0.0100036|           0.0100045|0.8435418820760986| 0.838678181468593|7.569990285951113E-7|\n",
      "|  6|           0.0100045|           0.0100054| 0.838678181468593| 0.833747551596085|7.525915798791051E-7|\n",
      "|  7|           0.0100054|0.010006300000000001| 0.833747551596085|0.8287504272925744|7.481240904998968E-7|\n",
      "|  8|0.010006300000000001|           0.0100072|0.8287504272925744|0.8236872483860601|7.435969540553856E-7|\n",
      "|  9|           0.0100072|           0.0100081|0.8236872483860601|0.8185584596564845|7.390105686191451E-7|\n",
      "| 10|           0.0100081|            0.010009|0.8185584596564845|0.8133645107934583|7.343653367024743E-7|\n",
      "+---+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+\n",
      "|           sum(area)|\n",
      "+--------------------+\n",
      "|0.003591786037420...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(start = 1, end = k+1).createOrReplaceTempView(\"TRAPEZOID\") ## Define the Id column\n",
    "## Use the 'Inteval' UDF to crate two columns containing the points that will be used in the next operation\n",
    "spark.sql(\"SELECT id, interval(id-1) as x0, interval(id) as x1 FROM TRAPEZOID\").createOrReplaceTempView(\"TRAPEZOID\") \n",
    "## Here we add the f, and Area columns to the TempView\n",
    "spark.sql(\"SELECT *, f(x0), f(x1), A(x0,x1) as area FROM TRAPEZOID\").createOrReplaceTempView(\"TRAPEZOID\")\n",
    "## Show the top 10 rows from the Temp View\n",
    "spark.sql(\"SELECT * FROM TRAPEZOID\").show(10)\n",
    "## In this line we calculate the sum of every trapezoid area, thus resulting in the defined integral value\n",
    "spark.sql(\"SELECT sum(area) FROM TRAPEZOID\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91489a12-9aa3-48dc-840d-7cdae5694dd7",
   "metadata": {},
   "source": [
    "*If you are not interested in the calculation tables, you can use just the block bellow which prints only the integral value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2af1557-e785-4d21-9d06-9f9cc5ef5871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035917860374208837"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(start = 1, end = k+1).createOrReplaceTempView(\"TRAPEZOID\")\n",
    "spark.sql(\"SELECT id, interval(id-1) as x0, interval(id) as x1 FROM TRAPEZOID\").createOrReplaceTempView(\"TRAPEZOID\")\n",
    "spark.sql(\"SELECT sum(A(x0,x1)) as area FROM TRAPEZOID\").collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c1412-6a7d-49db-a7d8-872f2a0e0a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
